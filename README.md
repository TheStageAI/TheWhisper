# ğŸ—£ï¸ TheWhisper: High-Performance Speech-to-Text Engine

[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Hugging Face](https://img.shields.io/badge/ğŸ¤—-Hugging%20Face%20Weights-yellow)](https://huggingface.co/)
[![NVIDIA](https://img.shields.io/badge/NVIDIA-GPU-green.svg)]()
[![Apple Silicon](https://img.shields.io/badge/Apple-Silicon-black.svg)]()

<img width="1500" height="440" alt="the whisper (6)" src="https://github.com/user-attachments/assets/a86c98a7-c587-40cb-9ed3-d3b5ba5e76f2" />

## ğŸš€ Overview

This repository provides **open-source transcription models** with **streaming inference support** and:
- Hugging Face open weights
- High-performance TheStage AI inference engines (NVIDIA GPU)
- CoreML engines for macOS / Apple Silicon with the lowest in the world power consumption for MacOS
- Local RestAPI with frontend examples using ReactJS and Electron

It is optimized for **low-latency**, **low power usage**, and **scalable** streaming transcription. <br>
Ideal for real-time captioning, live meetings, voice interfaces, and edge deployments.


<img width="1547" height="877" alt="apple m2 whisper" src="https://github.com/user-attachments/assets/f9a7ed1c-6c0a-4497-accd-f9adf57f6845" />

<details>
  <summary><strong>ğŸ“– Table of Contents</strong></summary>

- [ğŸš€ Overview](#-overview)
- [âœ¨ Features](#-features)
- [ğŸ—ï¸ Supported Platforms](#ï¸-supported-platforms)
- [ğŸ“¦ Installation](#-installation)
- [âš¡ Quick Start](#-quick-start)
- [ğŸ“ˆ Benchmarks](#-benchmarks)
  - [ğŸ Apple Silicon Benchmarks](apple_benchmarks.md)
  - [âš¡ NVIDIA GPU Benchmarks](nvidia_benchmarks.md)
- [ğŸ“œ License](#-license)
- [ğŸ¢ Enterprise License Summary](#-enterprise-license-summary)
- [ğŸ§ª Evaluation](#-evaluation)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ™Œ Acknowledgements](#-acknowledgements)
- [ğŸ“¬ Contact](#-contact)

</details>

---

## âœ¨ Features

- Open weights fine-tuned versions of Whisper models
- Fine-tuned models support inference with 10s, 15s, 20s and 30s
- CoreML engines for macOS and Apple Silicon, ~2W of power consumption, ~2GB RAM usage
- Optimized engines for NVIDIA GPUs through TheStage AI [ElasticModels](https://docs.thestage.ai/elastic_models/docs/source/index.html) (free for small orgs)
- Streaming implementation (NVIDIA + macOS)
- Benchmarks: latency, memory, power, and ASR accuracy (OpenASR)
- Simple Python API, Examples of deployment for MacOS desktop app with Electron and ReactJS



---

## ğŸ—ï¸ Supported Platforms

| Platform                 | Engine Type               | Status     | License                                 |
|--------------------------|---------------------------|------------|-----------------------------------------|
| NVIDIA GPUs (CUDA)       | TheStage AI (Optimized) | âœ… Stable  | Free â‰¤ 4 GPUs/year for small orgs       |
| NVIDIA GPUs (CUDA)       | Pytorch HF Transformers | âœ… Stable  | Free                                    |
| macOS / Apple Silicon    | CoreML Engine + MLX     | âœ… Stable  | Free                                    |

---

## ğŸ“¦ Installation

### 1. Clone the repository
```bash
git clone https://github.com/your-org/your-repo.git
cd your-repo
